{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1.0 \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "#Create monthes dict\n",
    "month_ua = {'січня': 1, 'лютого': 2, 'березня': 3, 'квітня': 4, 'травня': 5, 'червня': 6, 'липня': 7, 'серпня': 8,\n",
    " 'вересня': 9, 'жовтня': 10, 'листопада': 11, 'грудня': 12}\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:45.0) Gecko/20100101 Firefox/45.0'}\n",
    "\n",
    "#load the last dataset if it exists\n",
    "try:\n",
    "    latest_dataset = pd.read_csv('vacansies_dataset.csv')\n",
    "    latest_dataset_pd = latest_dataset[['id', 'title', 'time', 'requirements']].set_index('id')\n",
    "    existing_ids = latest_dataset.id\n",
    "    print('Number of existing vacancies:', len(existing_ids))\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print('There is no existing dataset')\n",
    "    latest_dataset_pd = pd.DataFrame()\n",
    "    existing_ids = pd.Series()\n",
    "\n",
    "pages = range(1,50)\n",
    "vacancies = []\n",
    "vac_dict = {}\n",
    "\n",
    "#loop by pages\n",
    "for p in pages:\n",
    "    url = 'https://www.work.ua/jobs-data+scientist/?page='+str(p) # url для первой страницы\n",
    "    page_response = requests.get(url, headers = headers)\n",
    "    page_content = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "\n",
    "\n",
    "    #find all vacancies on page\n",
    "    items_1 = page_content.find_all('div', {'class': 'card card-hover card-visited wordwrap job-link'})\n",
    "    items_2 = page_content.find_all('div', {'class': 'card card-hover card-visited wordwrap job-link js-hot-block'})\n",
    "    items = items_1 + items_2\n",
    "\n",
    "    #loop by items on each page\n",
    "    for item in items:\n",
    "        job_link = item.find('h2').find('a').get('href')\n",
    "        job_title_full = item.find('h2').find('a').get('title')\n",
    "        job_title = re.findall(r'(.*)\\,\\sвакансія\\sвід.*', job_title_full)[0]\n",
    "        ##job_desc = item.find('h2').find('a').text\n",
    "        #parse job_link to get id\n",
    "        job_id = re.match(r'\\/jobs\\/(\\d{7})', job_link)\n",
    "        if job_id:\n",
    "            job_id = job_id.group(1)\n",
    "            #Check if the job_id already exist in dataset\n",
    "            if int(job_id) in existing_ids.values:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        #parse job title to get date\n",
    "        job_date = re.match(r'.*вакансія\\sвід\\s(\\d{1,2})\\s(\\w*)\\s(\\d{4})', job_title_full).groups()\n",
    "        job_date_p = str(month_ua_dict[job_date[1]])+'/'+job_date[0]+'/'+job_date[2]\n",
    "        \n",
    "\n",
    "        # get job requirements and save to dictionary\n",
    "        \n",
    "        url_job = 'https://www.work.ua/jobs/' + job_id + '/'\n",
    "        page_response_job = requests.get(url_job, headers = headers)\n",
    "        page_content_job = BeautifulSoup(page_response_job.content, \"html.parser\")\n",
    "        cont = page_content_job.select(\"div.card.wordwrap ul\")\n",
    "        if len(cont)>1:\n",
    "            requirements = cont[1].get_text()\n",
    "            vac_dict.update({job_id:[job_title, job_date, job_date_p, requirements]})\n",
    "\n",
    "        else:\n",
    "            cont = page_content_job.select(\"div.card.wordwrap p\")\n",
    "            requirements = []\n",
    "            for t in cont[2:]:\n",
    "                item = t.get_text()\n",
    "                requirements = requirements + [item]\n",
    "                vac_dict.update({job_id:[job_title, job_date, job_date_p, requirements]})\n",
    "                \n",
    "# Import vacancies dictionary to pandas dataframe    \n",
    "vac_dict_pr = {'id': list(vac_dict.keys()), \n",
    "               'title': [ i[0] for i in list(vac_dict.values()) ], \n",
    "               'time': [i[2] for i in list(vac_dict.values())],\n",
    "              'requirements': [str(i[3]) for i in list(vac_dict.values())]}\n",
    "vac_df = pd.DataFrame(vac_dict_pr).set_index('id')\n",
    "\n",
    "print('Number of new vacancies:', len(vac_df))\n",
    "\n",
    "#Append new data to dataset\n",
    "new_dataset = vac_df.append(latest_dataset_pd)\n",
    "\n",
    "# Save pandas df to csv\n",
    "new_dataset.to_csv('vacansies_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
